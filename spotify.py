# -*- coding: utf-8 -*-
"""spotify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/adrian-spataru/stdm/blob/master/spotify.ipynb

# Spotify Dataset

This dataset contains audio statistics of the top 2000 tracks on Spotify. The data contains about 15 columns each describing the track and it's qualities. Songs released from 1956 to 2019 are included from some notable and famous artists like Queen, The Beatles, Guns N' Roses, etc.

Content

    Index: ID
    Title: Name of the Track
    Artist: Name of the Artist
    Top Genre: Genre of the track
    Year: Release Year of the track
    Beats per Minute(BPM): The tempo of the song
    Energy: The energy of a song - the higher the value, the more energtic. song
    Danceability: The higher the value, the easier it is to dance to this song.
    Loudness: The higher the value, the louder the song.
    Valence: The higher the value, the more positive mood for the song.
    Length: The duration of the song.
    Acoustic: The higher the value the more acoustic the song is.
    Speechiness: The higher the value the more spoken words the song contains
    Popularity: The higher the value the more popular the song is.


Here are some questions, you can trying answering to get you starting:

    Which genres were more popular coming through 1950s to 2000s?
    Songs of which genre mostly saw themselves landing in the Top 2000s?
    Which artists were more likely to make a top song?
    What is the average tempo of songs compared over the years?
"""

# !wget https://www.spataru.at/students/course_files/stdm/Spotify-2000.csv

"""# Libs"""

import pandas as pd
import numpy as np
import seaborn as sns

import matplotlib.pyplot as plt
import matplotlib.mlab as mlab
import matplotlib
plt.style.use('ggplot')
from matplotlib.pyplot import figure

"""# Data Preprocessing"""

df = pd.read_csv("Spotify-2000.csv")
df.head()


def data_set_info(dataFrame):
    print("Head:")
    print(dataFrame.head())
    print('-' * 70 + "\nShape:")
    print(dataFrame.shape)
    print('-' * 70 + "\nDatatypes:")
    print(dataFrame.dtypes)


def data_set_clean(dataFrame):
    # making all String columns lowercase to avoid inconsistency
    for col in dataFrame.columns:
        if dataFrame.dtypes[col] == 'object':
            dataFrame[col] = dataFrame[col].str.lower()
    # There are no duplicates nor NA values, but this stays in for demo purposes
    dfNoIx = dataFrame.drop('Index', axis=1).drop_duplicates()
    dfNoIx.dropna()
    print(dataFrame.shape)
    print(dfNoIx.shape)
    return dataFrame


def print_missing_percentage(dataFrame):
    print('-' * 70 + "\nMissing Data in %:")
    for col in dataFrame.columns:
        per_missing = np.mean(dataFrame[col].isnull())
        print('{} - {}%'.format(col, round(per_missing * 100)))


def create_histogram(dataFrame):
    for col in dataFrame.columns:
        dataFrame[col].hist()
        plt.show()


data_set_info(dataFrame=df)
print_missing_percentage(dataFrame=df)
# create_histogram(dataFrame=df)
# print(df["Year"].describe())
df = data_set_clean(dataFrame=df)
