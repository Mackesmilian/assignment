# -*- coding: utf-8 -*-
"""spotify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/adrian-spataru/stdm/blob/master/spotify.ipynb

# Spotify Dataset

This dataset contains audio statistics of the top 2000 tracks on Spotify. The data contains about 15 columns each describing the track and it's qualities. Songs released from 1956 to 2019 are included from some notable and famous artists like Queen, The Beatles, Guns N' Roses, etc.

Content

    Index: ID
    Title: Name of the Track
    Artist: Name of the Artist
    Top Genre: Genre of the track
    Year: Release Year of the track
    Beats per Minute(BPM): The tempo of the song
    Energy: The energy of a song - the higher the value, the more energtic. song
    Danceability: The higher the value, the easier it is to dance to this song.
    Loudness: The higher the value, the louder the song.
    Valence: The higher the value, the more positive mood for the song.
    Length: The duration of the song.
    Acoustic: The higher the value the more acoustic the song is.
    Speechiness: The higher the value the more spoken words the song contains
    Popularity: The higher the value the more popular the song is.


Here are some questions, you can trying answering to get you starting:

    Which genres were more popular coming through 1950s to 2000s?
    Songs of which genre mostly saw themselves landing in the Top 2000s?
    Which artists were more likely to make a top song?
    What is the average tempo of songs compared over the years?
"""

# !wget https://www.spataru.at/students/course_files/stdm/Spotify-2000.csv

"""# Libs"""

import pandas as pd
import numpy as np
import seaborn as sns

import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt

plt.style.use('ggplot')

"""# Data Preprocessing"""
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
df = pd.read_csv("Spotify-2000.csv")
df.head()


def data_set_info(dataFrame):
    print("Head:")
    print(dataFrame.head())
    print('-' * 70 + "\nShape:")
    print(dataFrame.shape)
    print('-' * 70 + "\nDatatypes:")
    print(dataFrame.dtypes)


def data_set_clean(dataFrame):
    # making all String columns lowercase to avoid inconsistency
    for col in dataFrame.columns:
        if dataFrame.dtypes[col] == 'object':
            dataFrame[col] = dataFrame[col].str.lower()
    # There are no duplicates nor NA values, but this stays in for demo purposes
    dfNoIx = dataFrame.drop('Index', axis=1).drop_duplicates()
    dfNoIx.dropna()
    print(dataFrame.shape)
    print(dfNoIx.shape)
    return dataFrame


def print_missing_percentage(dataFrame):
    print('-' * 70 + "\nMissing Data in %:")
    for col in dataFrame.columns:
        per_missing = np.mean(dataFrame[col].isnull())
        print('{} - {}%'.format(col, round(per_missing * 100)))


def create_histogram(dataFrame):
    for col in dataFrame.columns:
        dataFrame[col].hist()
        plt.show()


def univariate(dataFrame):
    for col in dataFrame.columns:
        print('-' * 70 + "\n")
        dfNew = pd.crosstab(index=dataFrame[col], columns='count')
        dfNew = dfNew.sort_values(['count'], ascending=False)
        print(dfNew.head())


data_set_info(dataFrame=df)
print_missing_percentage(dataFrame=df)
# create_histogram(dataFrame=df)
# print(df["Year"].describe())
df = data_set_clean(dataFrame=df)

# univariate(df)

dfCorr = df.drop('Index', axis=1).corr()
sns.heatmap(dfCorr, annot=True)
plt.rcParams["figure.figsize"] = [16, 9]
plt.show()
# df['Top Genre'].replace(to_replace='.*rock$', value='rock', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*pop$', value='pop', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*hip.*hop$', value='hip hop', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*indie$', value='indie', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*metal$', value='metal', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*funk$', value='funk', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*country$', value='country', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*jazz$', value='jazz', inplace=True, regex=True)
# df['Top Genre'].replace(to_replace='.*dance$', value='dance', inplace=True, regex=True)

dfGenres = pd.crosstab(index=df['Top Genre'], columns='count')
dfGenres = dfGenres.sort_values(['count'], ascending=False)
print(dfGenres.head())

dfRock = df.loc[df['Top Genre'] == 'rock']
print(dfRock[:30])
print(df.loc[df['Top Genre'] == 'rock'].describe())
dfPopularity = df[["Top Genre", "Popularity"]]
dfPopularity = dfPopularity.sort_values(['Popularity'], ascending=False)
print(dfPopularity[:30])
print(dfPopularity.describe())
print(df.groupby("Top Genre", as_index=False)["Popularity"].mean().sort_values(["Popularity"], ascending=False))
dfYearBpm = df.groupby("Year", as_index=False)["Beats Per Minute (BPM)"].mean().sort_values(["Year"], ascending=False)
print(df.groupby("Artist", as_index=False)["Popularity"].mean().sort_values(["Popularity"], ascending=False))
print(df[df['Year'].between(1960, 1963)])

# df.plot(kind='scatter', x="Year", y="Beats Per Minute (BPM)")
# dfYearBpm.plot(kind='line', x="Year", y="Beats Per Minute (BPM)")

ax = df.plot.scatter(x="Year", y="Beats Per Minute (BPM)", style='b')
dfYearBpm.plot.line(x="Year", y="Beats Per Minute (BPM)", ax=ax, style='g')
plt.show()

dfYearLoud = df.groupby("Year", as_index=False)["Loudness (dB)"].mean()
dfYearLoud.plot.line(x="Year", y="Loudness (dB)", style='b')
plt.show()

dfYearPop = df.groupby("Year", as_index=False)["Popularity"].mean()
dfYearPop.plot.line(x="Year", y="Popularity")
plt.show()

cols_to_remove = []

#df = df.drop(['Title', 'Artist', 'Length (Duration)'], axis=1)


genre_dict = dict(zip(df['Top Genre'], df['Top Genre']))
title_dict = dict(zip(df['Title'], df['Title']))
artist_dict = dict(zip(df['Artist'], df['Artist']))
length_dict = dict(zip(df['Length (Duration)'], df['Length (Duration)']))

# index = 0
# for k, v in area_dict.items():
#     area_dict[k] = index
#     index += 1


def replaceindict(dictToEdit):
    index = 0
    for k, v in dictToEdit.items():
        dictToEdit[k] = index
        index += 1


replaceindict(genre_dict)
replaceindict(title_dict)
replaceindict(artist_dict)
replaceindict(length_dict)

print(genre_dict)

df['Top Genre'].replace(genre_dict, inplace=True)
df['Title'].replace(title_dict, inplace=True)
df['Artist'].replace(artist_dict, inplace=True)
df['Length (Duration)'].replace(length_dict, inplace=True)

target_column = ['Energy']
predictors = list(set(list(df.columns)) - set(target_column))
df[predictors] = df[predictors] / df[predictors].max()
print(df.describe())

X = df[predictors].values
y = df[target_column].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)
print(X_train.shape)
print(X_test.shape)

lr = LinearRegression()
lr.fit(X_train, y_train)

pred_train_lr = lr.predict(X_train)
print(np.sqrt(mean_squared_error(y_train, pred_train_lr)))
print(r2_score(y_train, pred_train_lr))

pred_test_lr = lr.predict(X_test)
print(np.sqrt(mean_squared_error(y_test, pred_test_lr)))
print(r2_score(y_test, pred_test_lr))
